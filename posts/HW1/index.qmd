---
title: SQL Queries and Plotly Visualizations
author: Joshua Li
date: '2023-02-01'
categories:
  - code
  - analysis
jupyter: pic16b
---

In this blog post, we will be diving deeper into data visualization, specifically with plotly. By the end of this post, you will be able to:

1. [Create a database that stores tables](#step1)
2. [Utilize SQL to extract necessary data](#step2)
3. [Create a data visualization using plotly](#step3)

This article is a good exercise for the data visualization process. I will first go through the steps, and then provide additional examples.

## Create a Database {#step1}

First, we need to create a database that will store all the necessary data we need in order to create our visualizations. This is done through the `sqlite3` library. The `.csv` files were downloaded as toy datasets from a class curriculum.

```{python}
import sqlite3
import pandas as pd

# initialize a connection to new database
conn = sqlite3.connect("weather.db")

def create_table(df, out_name, **kwargs):
    '''
    Input:
    - df (str): path of the data frame
    - out_name (str): name of output table
    - **kwargs: keyword arguments for to_sql
    '''
    tbl = pd.read_csv(df) # reads csv
    tbl.to_sql(out_name, **kwargs) # transfers csv to sql database

# repetitive keywords
keywords = {'con': conn, 'index': False, 'if_exists': 'replace'}

# create 3 tables
create_table("temps_stacked.csv", "temperatures", **keywords)
create_table("countries.csv", "countries", **keywords)
create_table("station-metadata.csv", "stations", **keywords)

# verify that 3 tables are in the database
cursor = conn.cursor()
cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
print(cursor.fetchall())
conn.close() # close connection
```

After this code is run, we have a database labelled `weather.db`, containing 3 tables `temperatures`, `countries`, and `stations`. Here is a brief description of each table:

- `temperatures`: a list of temperature recordings of stations every month and year.
- `countries`: country names, their respective IDs, and abbreviations
- `stations`: station names, what country they are in, as well as latitude and longitude.

## Extract the Necessary Data {#step2}

Now, we need to achieve the necessary data and compile it into a file that we will use for the visualization. Each of the three tables contain important information and relationships that would be helpful if they were all merged together. We will write a function that takes a `SQL` query to take these tables, extract the necessary columns from each, and output a dataframe with all the information to create a visualization. I would encourage you to look at each of the tables and their columns to get a sense of what information there is. For the sake of this demonstration, this will be given to you. We want

- The station name
- The latitude of the station
- The longitude of the station
- The country where the station is located in
- The year the reading was taken
- The month the reading was taken
- The average temperature at this station at the given year and month

### Construct a SQL Query

This function we are able to make will only work if we extract the right information from the `SQL` query. This subsection will inform you of the `SQL` syntax, and some common tips.

#### 1. SQL Syntax

There are various keywords used in `SQL` that form a query. Here is a brief overview of the commands necessary for reading a table.

- `SELECT` - extracts columns from table
- `FROM` - used in conjunction with `SELECT` to specifies the table you are extracting from
- `(FULL|INNER|RIGHT|LEFT) JOIN` - joins two tables together (the four keywords denote if a table keeps all their data)
- `ON` - used in conjunction with `JOIN` keyword to specify the columns that link the two tables together
- `WHERE` - subsets the table to a given specification
- `GROUP BY` - similar to `pandas.groupby()`, groups table by specific columns
- `HAVING` - used in conjunction with `GROUP BY` to specify more subsetting within groups.
- `ORDER BY` - rearranges table to order by specific columns
- `DESC` - used in conjunction with `ORDER BY` to specify reverse ordering
- `LIMIT` - limits the number of rows outputted

#### 2. Common Tips

There are a couple queries that are commonly used in `SQL`. Here are some of them, and I will explain it all in detail

##### Example 1:
```sql
SELECT * FROM temperatures;
```

The * character denotes a wildcard, meaning all columns. This statement will extract all columns from the temperatures table.

##### Example 2:
```sql
SELECT year, month, temperature FROM temperatures
WHERE month = 12;
```

Get the year, month, and temperature from the temperatures table, subsetted only to the month of December.

##### Example 3:
```sql
SELECT t.id, t.temperature, s.name FROM temperatures t
INNER JOIN stations s
ON s.id = t.id;
```

Get the id and temperature from temperatures and name from stations, aliased as t and s, respectively.

##### Example 4:
```sql
SELECT t.id, t.temperature, s.name FROM temperatures t
INNER JOIN stations s
ON s.id = t.id
WHERE t.temperature > 20;
```

The same query as Example 3, but subsetted by temperatures greater than 20.

##### Example 5:
```sql
SELECT t.id, AVG(t.temperature), t.year, s.name FROM temperatures t
INNER JOIN stations s
ON s.id = t.id
GROUP BY t.year;
```

The same query as Example 3, but now calculating the average temperature grouped by year.

#### 3. Constructing the Query

Now that we have a better understanding of `SQL`, we will have to construct the query that will serve as the basis for this function. Here are the specs for the query, for your convenience:

- The station name
- The latitude of the station
- The longitude of the station
- The country where the station is located in
- The year the reading was taken
- The month the reading was taken
- The average temperature at this station at the given year and month
We can start by writing down the columns in a `SQL` format. However, these variables are not all found in the same table, so we need to join tables together in order for the initial query to work. Look into the tables in your own time to see that the relation key between the `temperatures` and `stations` tables is by their ID, and the relationship between `temperatures` and `countries` is by a subset of the ID corresponding with the countryâ€™s FIPS 10-4 code'.

```sql
SELECT s.Name, s.latitude, s.longitude, c.Name, t.year, t.month, t.temperature
FROM temperatures t
LEFT JOIN stations s ON t.id = s.id
LEFT JOIN countries c ON SUBSTRING(t.id, 1, 2) = c.[FIPS 10-4]
```

However, one of the things that we want to do is to specify subsetting by country, year and month. We can do this by adding the `WHERE` clause.

```sql
SELECT s.Name, s.latitude, s.longitude, c.Name, t.year, t.month, t.temperature
FROM temperatures t
LEFT JOIN stations s ON t.id = s.id
LEFT JOIN countries c ON SUBSTRING(t.id, 1, 2) = c.[FIPS 10-4]
WHERE c.NAME == "<country name>"
AND t.year < <year_end>
AND t.year > <year_begin>
AND t.month == <month>
```

This is the framework of the query we will use for the function.

### Constructing the Function

```{python}
import sqlite3
import pandas as pd
import numpy as np

conn = sqlite3.connect('weather.db')
def query_climate_database(country, year_begin, year_end, month):
    '''
    runs a SQL query that obtains temperature data for stations in a certain country for given years and months.
    @input:
    - country (str): (Official) Country Name 
    - year_begin (int): starting year to look for
    - year_end (int): end year to look for
    - month (int): which month to look at
    @output:
    - df: takes SQL results as a dataframe
    '''

    # SQL query
    cmd = '''
    SELECT s.Name, s.latitude, s.longitude, c.Name, t.year, t.month, t.temp
    FROM temperatures t
    LEFT JOIN stations s ON t.id = s.id
    LEFT JOIN countries c ON SUBSTRING(t.id, 1, 2) = c.[FIPS 10-4]
    WHERE c.NAME == \"{0}\"
    AND t.year <= {2} AND t.year >= {1}
    AND t.month == {3}'''.format(country, year_begin, year_end, month)

    # establish connection
    
    return pd.read_sql_query(cmd, conn) # return data frame

query_climate_database("India", 1980, 2020, 1)
```

## Creating a Data Visualization {#step3}

```{python}
import plotly.express as px
from sklearn.linear_model import LinearRegression

def LR_group_coef(df, x_cols, y_col):
    '''
    takes a data frame, runs a linear regression, finds the slope coefficient for the first column in x_cols
    @ input:
    - df (df): data frame to perform linear regression on
    - x_cols (list): list of string column names
    - y_col (str): response column name
    @ output:
    - first slope coefficient
    '''
    return LinearRegression().fit(df[x_cols], df[[y_col]]).coef_[0][0]

def temperature_coefficient_plot(country, year_begin, year_end, month, min_obs, **kwargs):
    '''
    plots an interactive geoscatter plot (plotly) with stations as points, with color denoting inferred yearly increase in temperature at that station for that given time period (years) and month.
    @input:
    - country (str): (official country name)
    - year_begin (int): when time period starts
    - year_end (int): when time period ends
    - month (int): which month to subset
    - min_obs (int): minimum number of observations a station must have for this data to run
    - **kwargs: keyword arguments for plotting
    @output:
    - figure: see description
    '''
    # get the necessary data
    df1 = query_climate_database(country, year_begin, year_end, month)

    # drop the stations that have less than n_obs values
    df2 = df1.copy()
    df2['n_obs'] = df2.groupby('NAME')['Month'].transform(len)
    df2['valid'] = df2['n_obs'] >= min_obs
    df = df2[df2['valid'] == True]
    df = df.drop(columns = ["n_obs", "valid"])

    # prep for regression
    X = df.drop(columns = ['Temp'])
    y = df[['Temp']]

    # find the average change in temp for each station
    model_coef = df.groupby('NAME').apply(LR_group_coef,
    x_cols = ['Year', 'Month'], y_col = 'Temp')

    # map it to the respective stations
    df['Average Temp Increase'] = np.round(df['NAME'].map(dict(model_coef)), 3)

    # recode months
    month_recode = {1: 'January',
    2: 'February',
    3: 'March',
    4: 'April',
    5: 'May',
    6: 'June',
    7: 'July',
    8: 'August',
    9: 'September',
    10: 'October',
    11: 'November',
    12: 'December'}

    # make the geoscatter plot
    title = "Estimates of yearly increase in temperature in {0}<br>for stations in {1}, years {2}-{3}".format(month_recode[month], country, year_begin, year_end)
    fig = px.scatter_mapbox(df, lat = 'LATITUDE', lon = 'LONGITUDE',
    color = 'Average Temp Increase', hover_name = 'NAME', color_continuous_midpoint = 0, title = title, **kwargs)

    fig.show(renderer = "notebook")
    # return df

color_map = px.colors.diverging.RdBu_r

temperature_coefficient_plot("India", 1980, 2020, 1, 10,
                                    zoom = 2,
                                   mapbox_style="carto-positron",
                                   color_continuous_scale=color_map)
```

Here is another plot for China in the same time period for January.

```{python}
temperature_coefficient_plot("China", 1980, 2020, 1, 10,
zoom = 2,
mapbox_style = 'carto-positron',
color_continuous_scale = color_map)
```

## Additional Examples

```{python}
def monthly_temp(country, year_begin, year_end):
    '''
    runs a SQL query that obtains temperature data for a station in a certain country for given years.
    @input:
    - country (str): (official country name)
    - year_begin (int): starting year to look for
    - year_end (int): end year to look for
    @output:
    - df: takes SQL results as a dataframe
    '''

    # SQL query
    cmd = '''
    SELECT s.Name, s.latitude, s.longitude, c.Name, t.year, t.month, t.temp
    FROM temperatures t
    LEFT JOIN stations s ON t.id = s.id
    LEFT JOIN countries c ON SUBSTRING(t.id, 1, 2) = c.[FIPS 10-4]
    WHERE c.Name == \"{0}\"
    AND t.year <= {2} AND t.year >= {1}'''.format(country, year_begin, year_end)

    # establish connection
    return pd.read_sql_query(cmd, conn) # return data frame

def median_monthly_temp(country, year_begin, year_end, **kwargs):
    '''
    shows the distribution of temperature by month for a station
    @ input:
    - country (str): (official country name)
    - year_begin (int): starting year to look for
    - year_end (int): end year to look for
    - **kwargs: keyword arguments for px.box
    @ output:
    fig: displays the boxplot
    '''

    # get necessary data
    df = monthly_temp(country, 1980, 2020)

    # recode month
    month_recode = {1: 'January',
    2: 'February',
    3: 'March',
    4: 'April',
    5: 'May',
    6: 'June',
    7: 'July',
    8: 'August',
    9: 'September',
    10: 'October',
    11: 'November',
    12: 'December'}
    df['Month'] = df['Month'].map(month_recode)

    # plot the box plot
    title = 'Distribution of Temperature by Month,<br>{0} {1}-{2}'.format(country, year_begin, year_end)
    fig = px.box(df, x="Month", y="Temp", title = title, **kwargs)
    fig.show(renderer = "notebook")

median_monthly_temp('India', 1980, 2020)
```

With this query, we extracted all the necessary information to show a distribution of temperature by month for a given country. In the example plot, we have a distribution of mean temperatures for each month in India. This helps to answer the question: **Which month is most likely to have the highest mean temperatures for a country?** We can see that through the visualization, it gives us that information, while also showing a general distribution to compare between months easily. This utilizes the box plot to help diminish the issue of missing data.

```{python}
def monthly_temp_time(country, year_begin, year_end, station, **kwargs):
    '''
    shows the trend of mean temperature by month for a station in a country
    @ input:
    - country (str): (official country name)
    - year_begin (int): starting year to look for
    - year_end (int): end year to look for
    - station (str): station name
    - **kwargs: keyword arguments for px.line
    @ output:
    fig: displays the lineplot
    '''
    
    # get necessary data
    df = monthly_temp(country, year_begin, year_end)

    # sort the dataframe
    sorted_df = df.copy()
    # map the value order
    sorted_df["order"] = sorted_df["NAME"].map({station: 1}).fillna(2)
    
    # recode months
    month_recode = {1: 'January',
    2: 'February',
    3: 'March',
    4: 'April',
    5: 'May',
    6: 'June',
    7: 'July',
    8: 'August',
    9: 'September',
    10: 'October',
    11: 'November',
    12: 'December'}
    sorted_df['Month'] = sorted_df['Month'].map(month_recode)
    # sort by this order
    sorted_df.sort_values(by=["order","Year"], ascending=False, inplace=True)

    # make the plot
    title = "Progression of Temperature in {0} by Month, {3} {1}-{2}".format(country, year_begin, year_end, station)
    fig = px.line(sorted_df, x = 'Year', y = 'Temp', color = 'NAME', **kwargs)
    fig.update_traces({"line":{"color":"lightgrey"}}) # hide unnecessary data
    fig.update_traces(patch={"line":{"color":"red", "width":3}}, 
                  selector={"legendgroup":station}) # highlight specific station
    fig.update_layout(title=title,
                showlegend=False,
                margin = {'l': 0, 'r':0, 't': 50, 'b': 0},
                width = 800,
                ) # format
    fig.show(renderer = "notebook")

monthly_temp_time('India', 1980, 2020, 'TEZPUR', facet_col = 'Month', facet_col_wrap = 4)
```

```{python}
conn.close()
```

This plot is created from the same query, but is now looking at trends over time. We ask the question: **What trends, if any, are there about the mean temperature by month over the years for a given station?** This utilizes a line plot to point out potential trends, and uses selective highlighting to point out a specific station with reference to other stations within the country. It also tells us about potential missing data, since not all lines start at the same point. For this particular station Tezpur, we do not see any particular trend for any given month, but that would have to be verified with numbers.

## Conclusion

Through this post, we learned how to create a database, how to construct and run queries, and to create cool data visualizations on plotly. As you get more familiar with plotly, I would highly recommend you look into the [official documentation](https://plotly.com/python/) to better customize your plots to fit your needs and what you need to convey to the audience.

