{
  "hash": "12383e1816f1dfe476b86e2e47274345",
  "result": {
    "markdown": "---\ntitle: Recommending Spotify Songs\nauthor: Joshua Li\ndate: '2023-03-25'\ncategories:\n  - code\n  - analysis\n---\n\n# 1. Introduction\n\nWith streaming services like Spotify, we have access to millions of songs at our fingertips. However, with so many options, it can be difficult to discover new artists and songs that we might enjoy. This is where recommendation systems come in.\n\nThis blog post is a recap of a final project for PIC16B W23 at UCLA. The goal of this project is to create a song recommendation system that would recommend songs for a given playlist. To do this, we utilized the Million Playlist Dataset, which Spotify provided for this purpose. There are 1 million playlists within this dataset, as the name suggests. With this data, we conducted our project through 4 main steps:\n\n1. Acquiring the data necessary for recommendation\n2. Cleaning the data\n3. Building the Recommendation System\n4. Connecting it with a website to host the recommendation system\n\nThis blog post will go through the process of creating a recommendation system step-by-step, as well as explain some of the methods we used to create it. We learned a lot through this project, and we hope that you do too! Now, let’s get into it. Here is a diagram of the project workflow.\n\n![Workflow](workflow.png)\n\n\nThe link to the repository for this project can be found here: https://github.com/joshuali19/pic16bproject\n\n# 2. Data Acquisition\n\n## Million Playlist Dataset\n\nThe first thing is to acquire the data necessary for this project. As mentioned in the introduction, we utilize the Spotify Million Playlist Dataset as our base dataset. This gives us each playlist in the form of a JSON file. Each playlist contains information about the playlist itself, like the number of songs, likes, playlist creator, etc. It also contains the information about the tracks within the playlist. For each track, there is information about the artist, the album it is a part of, and has unique identifiers for all of these things. This is all basic information that we can use. However, in order to build a recommendation system based on tracks and playlists, we need more than just demographic information of songs. We need to look into variables that would highlight specific features of songs. If you would like more information on the Million Playlist Dataset, please look at the [official challenge spec](https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge)\n\n![Playlist JSON File](playlist_json.png)\n\nAbove is the structure of the JSON file for an example playlist. This was provided by the provider of the Million Playlist Dataset, AICrowd. One can see all the playlist attributes listed, and the final one with all the tracks. In order to go through every single track in each playlist, we need to go through each of the different playlists and go through each of the tracks. After some experimentation, the fastest method was still to use a nested for loop to go through each element. However, this information given in the Million Playlist Dataset is not sufficient for our project.\n\n## Spotify API\n\nThis is where we need to connect to the Spotify API through `spotipy`. `spotipy` is a python library that allows users to connect to the Spotify API from the jupyter notebook, allowing access to get features from tracks, artists, and albums. To get this information, we need to have a secret key that we need to create via the [Spotify Developer Dashboard](https://developer.spotify.com/). Once you create a project from the dashboard, it will give you a key and a secret to allow you to access the Spotify database.\n\nHere is a diagram that displays the connection between the Million Playlist Dataset and the Spotify API.\n\n![API Connection](api.png)\n\nSpecifically, we want to look into getting the audio features of songs. These audio features are Spotify-created variables that describe a song quantitatively. Here is a list of the features that we use:\n\n- Danceability\n- Energy\n- Speechiness\n- Acousticness\n- Instrumentalness\n- Liveness\n- Valence\n- Loudness\n- Tempo\n- Mode\n- Key\n- Duration_ms\n- Time_signature\n\nFrom “danceability” to “valence”, the values range from 0 to 1, with 0 being the lowest score and 1 being the highest. With “loudness”, the range goes from -60 to 0, with units in decibels. The “tempo” is in beats per minute, and the “mode” and “key” are nonnegative integers. The “duration_ms” is how long the song is in milliseconds, and the “time_signature” is a value from 3 to 7 reflecting an estimated time signature. For a full description of what these variables mean, look at the [official Spotify docs](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features).\n\nWe can extract these audio features through `spotipy.get_audio_features(uri)`, which takes in a track URI, which is a unique identifier for a given Spotify track. Here is a method that shows how we extracted the audio features for the songs, and saved it in a dataframe. This is the basis for extracting the data. Given our limited time frame and lack of resources, we only were able to extract features for 1,000 of the 1 million playlists. To expand on this project, we would want to look at how it pans out over even more playlists, but for the sake of this post, we will only be using 1,000 playlists.\n\n```python\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport pandas as pd\nfrom time import sleep\n\n# Spotify credentials (unique to user) using different one to see if it works\nos.environ[\"SPOTIPY_CLIENT_ID\"] = \"***\"\nos.environ[\"SPOTIPY_CLIENT_SECRET\"] = \"***\"\nos.environ['SPOTIPY_REDIRECT_URI'] = \"http://localhost:5001\"\nsp = spotipy.Spotify(client_credentials_manager =      \n                     SpotifyClientCredentials(requests_timeout = 10))\ncols_to_keep = ['danceability', 'energy', 'key', 'loudness', 'mode',\n                'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n                'valence', 'tempo', 'duration_ms', 'time_signature']\ndfs = []\n\ndef extract_data(playlists, n):\n# can change playlists[0:n] depending on whether or not we want to include all the data.\ni = 0\n# for playlist in first 1000 playlists\nfor playlist in playlists[0:n]:\n    audio_feats = []\n    track_names = []\n    genres_list = []\n    artist_name = []\n    # for every 10 playlists\n    if i % 10 == 0:\n        print('Extracting playlist {0}...'.format(i))\n\n    # for each track in playlist\n    for track in playlist['tracks']:\n\n        # obtain track URI\n        track_uri = track['track_uri'].split(\":\")[2]\n        \n        # obtain artist URI\n        artist_uri = track['artist_uri'].split(\":\")[2]\n\n        # get audio features from spotify\n        feature = sp.audio_features(track_uri)\n        if feature:\n            audio_feats.append(feature[0])\n            track_names.append(track['track_name'])\n            artist_name.append(track['artist_name'])\n    # make data frame of audio features for songs in playlist\n    feats = pd.DataFrame(audio_feats)\n    # add identification data\n    feats['track_name'] = pd.Series(track_names)\n    feats['artist_name'] = pd.Series(artist_name)\n    feats['playlist_name'] = playlist['name']\n    feats['pid'] = playlist['pid']\n    # list of data frames, each data frame representing tracks in a playlist\n    i += 1\n    dfs.append(feats.T)\n    sleep(5)\n```\n\n# 3. Data Cleaning\n\nFrom the data acquisition, we were able to get the features of songs from 1,000 playlists and contain all of this information on a CSV file. However, we still need to do some proper cleaning. This CSV is not in the optimal format for us to use for our analysis.\n\n## Getting Rid of Duplicate Songs\n\nThe first thing that we need to do is to get rid of duplicate songs. Since we are reading in all songs from 1,000 playlists, and that some songs are extremely popular, it is highly likely that there will be songs that appear on multiple playlists. In terms of getting audio features, this is not helpful, so we need to omit these rows. Below is a function that we use to do that.\n\n```python\ndef drop_dups(df, cols):\n\treturn df.drop_duplicates(subset = cols) # dropping duplicate songs, on subset of cols\n```\n\n## Normalizing the Data\n\nNow that we have a dataset filled with only unique songs and their respective audio features, we can move forward with our processing of the data. Normalizing the data is a necessity in this project, because there are numeric variables that take on a wide range of values. For example, “danceability” has values from 0 to 1, while “duration_ms” has values that range from 0 to over 30000+. This may skew some of our results, placing too much weight on the “duration_ms” as opposed to other variables. To counteract this, we use a minimum-maximum scaler to normalize all numeric values to be between 0 and 1, based on the range in values for each feature. The logic and math behind it is shown below:\n\n![Min-Max Normalization Formula](minmax.png)\n\nThis is the method we used to create another CSV with only numeric variables reflecting the min-max normalization we mentioned above:\n\n```python\ndef norm_features(song_df):\n    '''\n    for the song df, normalize the numeric columns\n    @ inputs:\n    - song_df: df containing raw audio features of songs.\n    @ outputs:\n    - normalized_song_df: the normalized audio features of the songs\n    '''\n    # get numeric columns\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    num_df = song_df.select_dtypes(include=numerics)\n    \n    # scale these numeric columns\n    scaler = MinMaxScaler()\n    normalized_song_df = pd.DataFrame(scaler.fit_transform(num_df), columns = num_df.columns)\n    \n    normalized_song_df['uri'] = song_df['uri'].values\n    return normalized_song_df\n```\n\nWe now have the cleaned data to build a recommendation system!\n\n# 4. Building a Recommendation System\n\nThere are four different approaches to the recommendation system that we have attempted. \n\n## Audio Features\n\nAs mentioned above in the data cleaning, we sought to use the audio features from Spotify to help us create a recommendation system. Since we have a normalized data frame that was created above, we can use the normalized features for each song to represent a vector in a space. When we compare two songs, we are essentially comparing two vectors in the same vector space. To evaluate how “similar” two songs are to one another in this way, we utilize cosine similarity, which is looking at the angle between the two vectors to assess the similarity. If two vectors are the same (the same song), then cosine similarity will assign a score of 1, meaning that it is exactly similar, which makes sense. If the vector is pointed parallel, but in the opposite direction, the cosine similarity will assign a score of -1, meaning that they are not similar at all. Any angle in between will have a score between -1 and 1, with being closer to 1 meaning that the two songs are more similar. \n\n![Cosine Similarity](cosine.png)\n\nWe first utilize cosine similarity to assess the difference between two songs. This is done through our `get_similarity_scores()` method.\n\n```python\nfrom collections import Counter\n\ndef get_similarity_scores(df, feat_df, uri, n, model_type = cosine_similarity):\n    '''\n    gets the top n songs to recommend songs similar to one song.\n    @ inputs:\n    - df (pd.DataFrame): input dataframe with audio features\n    - song_title (str): title of track\n    - n (int): number of recommended songs\n    - model_type (df): gets the cosine similarity of big matrix\n    @ outputs:\n    - pandas series. of recommended songs\n    '''\n    # Get song indices\n    index=indices[uri]\n    \n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    num_df = feat_df.select_dtypes(include=numerics)\n    # print(index)\n    tfidf = model_type(num_df.iloc[index].values.reshape(1, -1), num_df[:].drop(index = index))[0]\n    # print(tfidf[0])\n    # Get list of songs for given songs\n    score=list(enumerate(tfidf))\n    # print(score)\n    # Sort the most similar songs\n    similarity_score = sorted(score,key = lambda x:x[1],reverse = True)\n    \n    return Counter(dict(similarity_score))\n```\n\nHowever, this only gets the similarity of one song compared to a whole data frame. How does this apply to a whole playlist? We use this function for each of the tracks, and then get an aggregate score for each recommended song. The logic of this approach is to assess the cosine similarity between all the songs in the playlist and all the songs in the normalized audio features data frame. We then add up all the scores by song id, and will take the top 10 songs based on this aggregate sum of cosine similarity. The method is shown below:\n\n```python\ndef get_top_songs(playlist, song_df, feat_df, n = 10):\n    total_score = Counter()\n    for track in playlist['tracks']:\n            total_score += get_similarity_scores(song_df, feat_df, \n                            track['track_uri'], 5)\n    topn_index = indices[sorted(dict(total_score), key = lambda x: x, reverse = True)[0:n]].index\n\n    return [song_df['track_name'][song_df['uri'] == uri].values[0] for uri in topn_index]\n```\n\nThis is most definitely not the best method, as these quantitative features are not clustered well by genre. Multiple genres may show similar values within certain features. I expect electronic dance music (EDM) and metal to score highly on the loudness metric, even though they are two completely different genres. One improvement to make with this is to incorporate the genres of the songs with the audio features to make better assessments and recommendations.\n\nIn order to accept the playlist ID, we needed to build a function that could use the playlist ID and call the Spotify API to return the track URIs for the tracks in the playlist. First, we will use the `spotipy` library to access the playlist, set up authorization using the Spotify client ID and secret, and retrieve the list of track URIs and names. Then, we will create a list of dictionaries where each dictionary has a key `track_uri` with a value of the URI of a track. The output would be a dictionary with one key called tracks that has a value that is the list of dictionaries created above. This mimics the format of the playlists that come from a json file, so that the output can be passed into `get_top_songs()`. The function that handles this is defined below:\n\n```python\ndef get_playlist_track_URIs(playlist_id):\n    '''\n    gets the track URIs from a Spotify playlist\n    @ inputs:\n    - playlist_id (str)\n        The unique identifier for the Spotify playlist.\n    @ output:\n    dict containing: track_uris (list of str)\n                         A list of the track URIs for all tracks in the playlist.\n                     track_names (list of str)\n                            A list of the track names for all tracks in the playlist.\n    '''\n    # Set up authorization using the Spotify client ID and secret\n    client_credentials_manager = SpotifyClientCredentials(client_id='bdf64242b8364ab5b264d3c14e8e9af6', client_secret='3ed931eb80d8412292a50a10ed96e611')\n    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n    \n    # Get track URIs and names from playlist\n    results = sp.playlist_tracks(playlist_id)\n    tracks = results['items']\n    playlist_tracks = []\n    for track in tracks:\n        track_uri = track['track']['uri']\n        playlist_tracks.append({'track_uri': track_uri})\n    \n    return {\"tracks\": playlist_tracks}\n```\n\n# 5. Building A Website to Host Recommendation System\n\nNow, we need to take all of these components into consideration when making our website. For this project, we use Flask to run our web app. On our home page, we have the recommendation app itself. It can take either a playlist id or a JSON file representing a playlist as its input, and it will output the recommendations after clicking “Submit”. The styling was based on trial and error, using official Spotify colors. The second page we built was the about page, where you can see all of our contact information.\n\n** INSERT PHOTO OF WHAT THE APP LOOKS LIKE **\n![Application Home](page.png)\n\n** INSERT PHOTO OF PLAYLIST RECOMMENDATIONS **\n![Playlist Recommendations](recs.png)\n\nThere are three pages on our website: Get Recommendations, About, and How to Find Playlist ID. Accordingly, there are three functions used to define these three pages. \n\nThe first function we will walk through is the Get Recommendations page. In this function, if the method is GET, it returns the rendered HTML template defined in `recommend.html`. Otherwise, if the method is POST, it processes the input data to find the top recommended songs based on a user's submitted playlist using `get_playlist_track_URIs()` if a playlist ID is inputted and `get_file()` if a file is uploaded. In either case, `get_top_songs()` will be run to produce the recommendations once the playlist is identified. If the recommendation process is successful, it returns the rendered HTML template `recommend.html` displaying the top recommended songs. If there is an error during the process, it will return an error message.\n\n```python\n@app.route('/', methods=['POST', 'GET'])\ndef recommend():\n    if request.method == 'GET':\n        return render_template('recommend.html') # default recommend.html display\n    else: # if someone posts\n        try:\n            # get playlist, and find top songs\n            playlist = request.form['playlist_id']\n            \n            # checks to see if playlist has been submitted as ID or json file\n            if not playlist:\n                playlist = get_file(request)\n            else:\n                # get track URIs and names from playlist using Spotify API\n                playlist = get_playlist_track_URIs(playlist)\n            \n            top_songs = get_top_songs(playlist, song_df, feats_df)\n            # display the top songs\n            return render_template('recommend.html', recs = top_songs)\n        except:\n            # return an error\n            return render_template('recommend.html', error = True)\n```\n\nThe second function creates a simple About page. It will render a page with information about the creators that is defined in `about.html`. The construction of this function is similar to that of the function defined previously.\n\n```python\n@app.route('/about/')\ndef about():\n    try:\n        # about page for creators\n        return render_template('about.html', msgs = msgs)\n    except:\n        # return an error\n        return render_template('about.html', error = True)\n```\n\nLastly, we will create a third function that creates a page that instructs the user on how to obtain the spotify playlist ID of any playlist. Similar to the function defining the About page, this function will render an HTML template that is defined in `tutorial.html`.\n\n```python\n@app.route('/tutorial/')\ndef tutorial():\n    try:\n        # tutorial page for how to find playlist id\n        return render_template('tutorial.html', msgs = msgs)\n    except:\n        # return an error\n        return render_template('tutorial.html', error = True)\n```\n\n# 6. Conclusion\n\nCreating this Spotify recommendation system involved four main steps: acquiring data, cleaning data, building the recommendation algorithm, and connecting it with a website. The Million Playlist Dataset provided by Spotify was used to acquire playlist information, and the Spotify API (reached via the spotipy library) was used to obtain audio features of songs. Data cleaning involved removing duplicate songs and normalizing data. Building the recommendation system involved cosine similarity measures to determine songs that have similar audio features. Finally, the system was deployed on a Flask web application where users could input a playlist, and the system would provide a list of song recommendations.\n\nDeveloping a Spotify recommendation system using Million Playlist Dataset and the Spotify API can be a rewarding and fun project for anyone interested in data science and music. Additionally, with the power of Flask, you can create a simple interface that allows users to submit their playlists and receive song recommendations in real-time. There are not too many ethical implications with our data. It may use user data, but since it is not hosted on cloud, nor stored on a database, there is no data that is being stored that would have the potential to be leaked. Overall, this project is an excellent way to explore how data science can be used for music and to explore various APIs and Python libraries.\n\n## GitHub Repository\n\nHere is the [GitHub repository](https://github.com/joshuali19/pic16bproject) if you would like to check it out.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}